<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Demo</title>
  <link rel="stylesheet" href="/css/style.css">
  
    <link rel="shortcut icon" href="/favicon.ico">
  
<meta name="generator" content="Hexo 7.3.0"></head>
<body>
  <header class="header">
    <div class="container">
      <div class="logo-container">
        <a href="/" class="logo">
          
            <img src="/images/logo.png" alt="Demo">
          
        </a>
      </div>
      <nav class="main-nav">
        
          <a href="/" class="nav-item">首页</a>
        
          <a href="/tags" class="nav-item">标签</a>
        
      </nav>
    </div>
  </header>

  <main class="main-content">
    <div class="container">
      <article class="post-content">
  <header class="post-header">
    <h1 class="post-title"></h1>
    <div class="post-meta">
      <span class="post-date">2025-04-30</span>
      
    </div>
  </header>
  
  <div class="post-body">
    <div align='center'><font size='6'> <b>中山大学计算机学院本科生实验报告
<div align='center'><font size='4'> <b>（2024学年春季学期）</b>

<p>课程名称：并行程序设计																	批改人：</p>
<table>
<thead>
<tr>
<th>实验</th>
<th>2-基于MPI的并行矩阵乘法（进阶）</th>
<th>专业（方向）</th>
<th>计算机科学与技术（系统结构）</th>
</tr>
</thead>
<tbody><tr>
<td>学号</td>
<td>21307304</td>
<td>姓名</td>
<td>陈钰冰</td>
</tr>
<tr>
<td>Email</td>
<td><a href="mailto:&#99;&#104;&#101;&#x6e;&#x79;&#x62;&#56;&#53;&#x40;&#x6d;&#x61;&#105;&#x6c;&#50;&#x2e;&#115;&#121;&#115;&#x75;&#x2e;&#x65;&#x64;&#117;&#x2e;&#99;&#x6e;">&#99;&#104;&#101;&#x6e;&#x79;&#x62;&#56;&#53;&#x40;&#x6d;&#x61;&#105;&#x6c;&#50;&#x2e;&#115;&#121;&#115;&#x75;&#x2e;&#x65;&#x64;&#117;&#x2e;&#99;&#x6e;</a></td>
<td>完成日期</td>
<td>2024.4.6</td>
</tr>
</tbody></table>
<p>[TOC]</p>
<h2 id="一、实验目的"><a href="#一、实验目的" class="headerlink" title="一、实验目的"></a>一、实验目的</h2><p>​	1. 采用MPI<strong>集合通信</strong>实现并行矩阵乘法中的进程间通信；使用<code>mpi_type_create_struct</code>聚合MPI进程内变量后通信；尝试不同数据&#x2F;任务划分方式（选做）。</p>
<ol start="2">
<li>对于不同实现方式，调整并记录不同线程数量（1-16）及矩阵规模（128-2048）下的时间开销，填写下页表格，并<strong>分析其性能及扩展性</strong>。</li>
</ol>
<h2 id="二、实验过程和核心代码"><a href="#二、实验过程和核心代码" class="headerlink" title="二、实验过程和核心代码"></a>二、实验过程和核心代码</h2><h4 id="集合通信"><a href="#集合通信" class="headerlink" title="集合通信"></a>集合通信</h4><table>
<thead>
<tr>
<th>求最大值、求最小值、求累加和、求累乘积、逻辑与、按位与</th>
<th><code>MPI_Reduce()</code></th>
</tr>
</thead>
<tbody><tr>
<td>求有关全局的量同时通知每个进程</td>
<td><code>MPI_Allreduce()</code></td>
</tr>
<tr>
<td>将某个进程的数据进行广播</td>
<td><code>MPI_Bcast()</code></td>
</tr>
<tr>
<td>散射，对于可以整除的大小进行块划分后分发</td>
<td><code>MPI_Scatter()</code></td>
</tr>
<tr>
<td>聚集，将分发的分量进行聚集</td>
<td><code>MPI_Gather()</code></td>
</tr>
<tr>
<td>全局聚集，从每个进程收集一个数据项，并将其发送到所有其他进程</td>
<td><code>MPI_Allgather()</code></td>
</tr>
</tbody></table>
<h4 id="集合通信实现并行矩阵乘法中的进程间通信"><a href="#集合通信实现并行矩阵乘法中的进程间通信" class="headerlink" title="集合通信实现并行矩阵乘法中的进程间通信"></a>集合通信实现并行矩阵乘法中的进程间通信</h4><p>流程图：绿色对应my_rank&#x3D;&#x3D;0单独的操作，蓝色对应集合通信和所有进程的操作。</p>
<img src="C:\Users\86136\AppData\Roaming\Typora\typora-user-images\image-20240407204719849.png" alt="image-20240407204719849" style="zoom:67%;" />

<p>初始化缓存区：</p>
<p> <img src="C:\Users\86136\AppData\Roaming\Typora\typora-user-images\image-20240407205020034.png" alt="image-20240407205020034" style="zoom: 65%;" />!</p>
<p>初始化A、B矩阵：</p>
 <img src="C:\Users\86136\AppData\Roaming\Typora\typora-user-images\image-20240407205052901.png" alt="image-20240407205052901" style="zoom:55%;" />



<p>分发和广播：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//分发矩阵A</span></span><br><span class="line"><span class="built_in">MPI_Scatter</span>(matrix_A.<span class="built_in">data</span>(),line*size,MPI_INT,local_A.<span class="built_in">data</span>(),line*size,MPI_INT,<span class="number">0</span>,MPI_COMM_WORLD);</span><br><span class="line"></span><br><span class="line"><span class="comment">//广播矩阵B</span></span><br><span class="line"><span class="built_in">MPI_Bcast</span>(matrix_B.<span class="built_in">data</span>(),size*size,MPI_INT,<span class="number">0</span>,MPI_COMM_WORLD);</span><br></pre></td></tr></table></figure>



<p>计算：</p>
 <img src="C:\Users\86136\AppData\Roaming\Typora\typora-user-images\image-20240407205251338.png" alt="image-20240407205251338" style="zoom:67%;" />



<p>结果聚集：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">MPI_Gather</span>(ans.<span class="built_in">data</span>(),line*size,MPI_INT,matrix_C.<span class="built_in">data</span>(),line*size,MPI_INT,<span class="number">0</span>,MPI_COMM_WORLD);</span><br></pre></td></tr></table></figure>



<p>写入文件：</p>
 <img src="C:\Users\86136\AppData\Roaming\Typora\typora-user-images\image-20240407205347958.png" alt="image-20240407205347958" style="zoom:55%;" />



<h4 id="MPI的派生数据类型"><a href="#MPI的派生数据类型" class="headerlink" title="MPI的派生数据类型"></a>MPI的派生数据类型</h4><p>在分布式内存中，通信比本地计算开销大得多，因此减少发送的消息数量能够提高程序的性能。常用的整合多条消息的数据的三种手段为：1. 通信函数中的count、2. 派生数据类型、3. MPI_Pack&#x2F;Unpack函数</p>
<p>在矩阵乘法的例子中，my_rank&#x3D;&#x3D;0将matrix_A分发给所有的进程，每个进程则获得line行的数据。将这line行的数据（其实是一个line*size的矩阵）作为整体形成一种派生数据类型。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//定义MPI的数据类型——每个block:line×size的矩阵</span></span><br><span class="line">MPI_Datatype aBlock;</span><br><span class="line"></span><br><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">blocklengths</span><span class="params">(line,size)</span></span>; 			<span class="comment">// 每个部分的数据个数  </span></span><br><span class="line"><span class="function">vector&lt;MPI_Datatype&gt; <span class="title">types</span> <span class="params">(line, MPI_INT)</span></span>; 	<span class="comment">// 每个部分的数据类型  </span></span><br><span class="line"><span class="function">vector&lt;MPI_Aint&gt; <span class="title">displs</span><span class="params">(line)</span></span>; 					<span class="comment">// 每个部分的位移 </span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;line;i++)&#123;</span><br><span class="line">        displs[i]=i*size*<span class="built_in">sizeof</span>(<span class="type">int</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">MPI_Type_create_struct</span>(line, blocklengths.<span class="built_in">data</span>(), displs.<span class="built_in">data</span>(), types.<span class="built_in">data</span>(), &amp;aBlock); <span class="built_in">MPI_Type_commit</span>(&amp;aBlock);  </span><br></pre></td></tr></table></figure>



<p>在0号进程进行分发：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//分发</span></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;comm_sz;i++)&#123;</span><br><span class="line">    <span class="comment">//发送</span></span><br><span class="line">    <span class="built_in">MPI_Send</span>(matrix_A.<span class="built_in">data</span>()+(i<span class="number">-1</span>)*line*size, <span class="number">1</span>, aBlock, i, <span class="number">1</span>, MPI_COMM_WORLD);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>其他进程接收：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 接收</span></span><br><span class="line"><span class="built_in">MPI_Recv</span>(local_A.<span class="built_in">data</span>(), <span class="number">1</span>, aBlock, <span class="number">0</span>, <span class="number">1</span>, MPI_COMM_WORLD, MPI_STATUS_IGNORE);</span><br></pre></td></tr></table></figure>



<p>最后记得释放：</p>
 <img src="C:\Users\86136\AppData\Roaming\Typora\typora-user-images\image-20240408155517866.png" alt="image-20240408155517866" style="zoom:57%;" />



<h2 id="三、实验结果"><a href="#三、实验结果" class="headerlink" title="三、实验结果"></a>三、实验结果</h2><h4 id="集合通信实现结果："><a href="#集合通信实现结果：" class="headerlink" title="集合通信实现结果："></a>集合通信实现结果：</h4><table>
<thead>
<tr>
<th>进程数|矩阵规模</th>
<th>128</th>
<th>256</th>
<th>512</th>
<th>1024</th>
<th>2048</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>0.011451</td>
<td>0.085853</td>
<td>0.57885</td>
<td>5.21234</td>
<td>45.33515</td>
</tr>
<tr>
<td>2</td>
<td>0.009788</td>
<td>0.048422</td>
<td>0.33325</td>
<td>3.31360</td>
<td>24.0411</td>
</tr>
<tr>
<td>4</td>
<td>0.007798</td>
<td>0.033864</td>
<td>0.24392</td>
<td>2.12417</td>
<td>18.7567</td>
</tr>
<tr>
<td>8</td>
<td>0.007378</td>
<td>0.033887</td>
<td>0.19589</td>
<td>1.60592</td>
<td>13.6127</td>
</tr>
<tr>
<td>16</td>
<td>0.008302</td>
<td>0.035520</td>
<td>0.21656</td>
<td>1.465</td>
<td>12.479</td>
</tr>
</tbody></table>
<h4 id="MPI派生类型实现结果："><a href="#MPI派生类型实现结果：" class="headerlink" title="MPI派生类型实现结果："></a>MPI派生类型实现结果：</h4><table>
<thead>
<tr>
<th>进程数|矩阵规模</th>
<th>128</th>
<th>256</th>
<th>512</th>
<th>1024</th>
<th>2048</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>0.01610</td>
<td>0.11698</td>
<td>0.89707</td>
<td>8.631</td>
<td>54.5846</td>
</tr>
<tr>
<td>2</td>
<td>0.01454</td>
<td>0.06331</td>
<td>0.51373</td>
<td>4.9868</td>
<td>34.5254</td>
</tr>
<tr>
<td>4</td>
<td>0.14026</td>
<td>0.05476</td>
<td>0.34466</td>
<td>2.7162</td>
<td>21.59</td>
</tr>
<tr>
<td>8</td>
<td>0.11245</td>
<td>0.04914</td>
<td>0.23826</td>
<td>1.9612</td>
<td>14.7648</td>
</tr>
<tr>
<td>16</td>
<td>0.20829</td>
<td>0.04384</td>
<td>0.26273</td>
<td>2.1055</td>
<td>14.8473</td>
</tr>
</tbody></table>
<h4 id="Lab1中的实验结果："><a href="#Lab1中的实验结果：" class="headerlink" title="Lab1中的实验结果："></a>Lab1中的实验结果：</h4><img src="C:\Users\86136\AppData\Roaming\Typora\typora-user-images\image-20240408190006591.png" alt="image-20240408190006591" style="zoom:67%;" />



<h4 id="性能及扩展性分析："><a href="#性能及扩展性分析：" class="headerlink" title="性能及扩展性分析："></a>性能及扩展性分析：</h4><ol>
<li><strong>Lab1的实验结果和集合通信的实验结果对比</strong>，主要体现在集合通信和点对点通信上面。由于不再是只有主进程串行地发送和接收数据，使得通信成本降低，使得总体项目的运行时间变快。并且可以看出，随着矩阵规模的变大，加速越加明显。</li>
<li><strong>Lab1的实验结果和MPI派生类型的实验结果对比</strong>，由于两者其实都是基于整合多条消息的数据的手段：count和派生数据类型，从结果上来看其实两者并无太大差异。貌似随着矩阵规模变大，后者比前者的表现会更好。</li>
</ol>
<h2 id="四、实验感想"><a href="#四、实验感想" class="headerlink" title="四、实验感想"></a>四、实验感想</h2><p>实验过程中遇到的困难：</p>
<ol>
<li>MPI的接口很多，参数也很多，准确理解和应用显得十分重要。实验过程中，对<code>MPI_Type_create_struct()</code>中的<code>array_of_displacements</code>的理解一直存在偏差。曾误以为为与每一项的真实地址、前一项的偏移差等，导致代码无法运行。更多的例子还有，<code>MPI_Send</code>和<code>MPI_Recv</code>中的参数<code>buf_size</code>，其代表着对应的存储对象的个数，所以当参数类型变成自定义的类型时，其也需要改变。</li>
<li>报错信息很模糊，无法精确定位出错位置。</li>
</ol>
<p>实验总结：</p>
<ol>
<li>本次实验过程中，经由代码实现，我对这几个函数的运用有了一定程度的认识。</li>
<li>认识了集合通信在涉及多个进程通信中的原理和优势</li>
</ol>

  </div>
  
  
</article>


  <div class="post-navigation">
    
      <a href="/2025/04/30/%E6%9B%B4%E6%96%B0%E5%8D%9A%E5%AE%A2%E6%95%99%E7%A8%8B/" class="post-nav-prev">
        <span class="post-nav-label">上一篇</span>
        <span class="post-nav-title">更新博客教程</span>
      </a>
    
    
      <a href="/2025/04/30/hello-world/" class="post-nav-next">
        <span class="post-nav-label">下一篇</span>
        <span class="post-nav-title">Hello World</span>
      </a>
    
  </div>


    </div>
  </main>

  <footer class="footer">
    <div class="container">
      <div class="copyright">
        &copy; 2025 John Doe
      </div>
      
        <div class="footer-links">
          
            <a href="/about" class="footer-link">关于我们</a>
          
            <a href="/contact" class="footer-link">联系方式</a>
          
            <a href="/privacy" class="footer-link">隐私政策</a>
          
            <a href="/terms" class="footer-link">服务条款</a>
          
        </div>
      
    </div>
  </footer>

  
    
      <script src="/js/main.js"></script>
    
  
</body>
</html>
